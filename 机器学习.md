# 数学

# 一：线性代数

## 1：线性方程组

关键字：

**线性方程**：形如  a<sub>1</sub>x<sub>1</sub>+a<sub>2</sub>x<sub>2</sub>+a<sub>3</sub>x<sub>3</sub>+....+a<sub>n</sub>x<sub>n</sub>=b

其中a<sub>1</sub> ，a<sub>2</sub>....和b是常数

其他是未知数

**线性方程组**：就是几个线性方程在一起组成一个方程组

**解集**：方程组所有的解被称为解集

一个线性方程组的解只有以下三种情况

1. 有无穷解
2. 仅有唯一解
3. 无解

**系数矩阵**：就是把线性方程组的系数弄下来，形成矩阵

矩阵的一行就是第一个线性方程的系数集合

**增广矩阵**：比系数矩阵多了一列，里面放“=”右边的常数

矩阵的三种基本的**行初等变化**

1. **倍加变换**，就是把矩阵的第j行，乘以某一倍数，再加到矩阵的第i行上。

   举例子
   
   ```
   1，-2，1，0
   0，2，-8，8
   -4，5，9，-9
   ```
   
   现在把第一行乘以4，得到
   
   `4,-8,4,0`
   
   接下来用这个新行加上最后一行。得到新的矩阵是
   
   ```
   1，2，1，0
   0，2，-8，8
   0,-3,13, 9 
   ```
   
   这就是倍加变换了。
   
   其实是从解线性方程组得到的
   
   x<sub>1</sub>-2x<sub>2</sub>+x<sub>3</sub>=  0
   2x<sub>2</sub> -8x<sub>3</sub>= 8
   -4x<sub>1</sub>+ 5x<sub>2</sub> + 9x<sub>3</sub>= -9
   
   将第一个方程乘以4，然后加在第三个方程，以求消掉x1
   
2. **对换交换**（就是将矩阵的两个行交换位置）

   对应到线性方程组上，就是交换两个线性方程的位置

   大概这样更顺眼一点。。

3. **将矩阵的某一行乘一个非零的倍数**。

   没啥好说的，就是字面意思，

以上初等变换，都是从解线性方程组的过程中总结而来的



**两个矩阵行对价**：就是A矩阵经过初等变换，可以变成另一个矩阵，则两个矩阵就是行对价



行变换是可逆的，也很容易理解



如果两个线性方程组的增广矩阵是行等价的，则他们有相同的解集



其实我们可以通过增广矩阵，来得知对应的线性方程组是否有唯一解，无解，或无限解

将增广矩阵用行初等变换算到一定程度后，再换算成线性方程组，可能会得到一个矛盾的解集，那么就说明这个线性方程组是无解的



**三角矩阵**：矩阵内非零系数排列起来像是三角形一样

举例子

![avatar](https://raw.githubusercontent.com/XHang/Notes/master/image/%E4%B8%89%E8%A7%92%E7%9F%A9%E9%98%B5.png)



## 2：行化简和阶梯型矩阵

关键字

**矩阵中的非零行或非零列**： 指的是矩阵中某行或某列元素不全为零的行或列

**非零行的先导元素**:指的是矩阵中非零行最左边的元素

**阶梯型矩阵**（行阶梯型矩阵）定义：

1.  每一非零行在每一零行之上（只要是上面即可，没有位置要求）

   > 或者说非零行上面没有零行

2. 某一行的先导元素在前一行先导元素的右边

   > 形似阶梯

3. 某一先导元素的所在列，下方元素全是0（2的推论）

   > 比如说第1行，第3列是第一行的先导元素
   >
   > 则：	第2行，第三列的元素必须是0
   >
   > ​			第3行，第三列的元素必须是0
   >
   > ​			第4行，第三列的元素必须是0
   >
   > ​			 .......

**简化阶梯型（简化行阶梯型矩阵）**定义

首先该矩阵必须先符合上面的三个定义，也就是说，它自己得是阶梯型矩阵，然后再来符合以下特点

1. 每一个非零行的先导元素是1
2. 每一个先导元素，除了它自己，所在列的其他元素，全是0

**一个结论**：

一个矩阵可以通过不同的行化简（行初等变换）化成不同的阶梯型矩阵。

但是化到最后，只能有唯一的简化阶梯型矩阵

**一个定理**：

每个矩阵行等价于唯一的简化阶梯形矩阵

> 其实有点不太科学哦，上面的定义有些不太符合

一个矩阵无论经过多少行变换成阶梯型矩阵，它的先导元素位置总是固定的

**主元位置**：是矩阵中的一个元素，通常和零是不同的，主要是用来通过算法消去元用的

> pivot element

**主元列**：接着上面的话题，A矩阵中，含有主元位置的列，就是主元列

**主元**：其实就是主元位置上，非零的元素（这不多余不？，主元位置只能有一个元素，主元也只能是它了）

**向前步骤**：当一个矩阵化成阶梯型矩阵时，所经历的步骤叫做向前步骤。

**向后步骤**：当一个阶梯型矩阵继续向下化成简化阶梯型矩阵时，所经历的步骤叫向后步骤

**基本变量**：从阶梯型矩阵转成的线性方程组，其主元位置所在的未知数，叫做基本变量，其他的未知数，叫自由变量

**怎么显示表示相容线性方程组的表达式**

只要把它们的增广矩阵化到简化阶梯型矩阵即可

这样就能保证在方程组中，一个方程中，只有一个基本变量。

这个时候，再用自由变量来表示基本变量即可。

举个栗子,有个线性方程组如下

x<sub>1</sub> —5x<sub>3</sub> = 1
x<sub>2</sub>+ x<sub>3</sub> = 4
0 =0

化成增广矩阵如下


![简化阶梯型矩阵](https://raw.githubusercontent.com/XHang/Notes/master/image/%E7%AE%80%E5%8C%96%E9%98%B6%E6%A2%AF%E5%9E%8B%E7%9F%A9%E9%98%B5%E7%A4%BA%E4%BE%8B.png)

很好，已经是简化阶梯型矩阵了

从这个矩阵我们可以看到，x<sub>1</sub>  x<sub>2</sub>  就是基本变量，余下的x<sub>3</sub>就是自由变量了

然后我们要用自由变量来表示基本变量，于是方程组变成了

x<sub>1</sub> = 1+5x<sub>3</sub>

x<sub>2</sub> = 4-x<sub>3</sub>

然后，这个方程组的解集是：当X<sub>3</sub>  取任意值时，x<sub>1</sub>  x<sub>2</sub> 的值都能唯一确定

这个解也被称为方程组的通解，因为它给出了所有解的通俗解释

**判断一个方程组是否解集情况**

1. 化成增广矩阵

2. 化成阶梯型

3. 包含0=b的情况吗？
   1. 包含：无解
   2. 不包含
   
4. 化成简化阶梯型

5. 是否存在自由变量

   存在：无限解

   不存在：唯一解



**确定一个矩阵的主元列，并化成阶梯型**

1. 首先确定矩阵中的主元列，一般选择最右且非零列，然后在该列选一个非零元素作为主元，然后将该主元列和最上列交换位置
2. 用主元所在列，去乘以一个数，然后去加另外一个列，用以消去其他同列的元素（此乃倍加消除法）
3. 重复以上步骤，直至化解得到的矩阵是阶梯型矩阵

定理：线性方程组有解的充要条件是：增广矩阵的主元列不是最右列，也就是，避免这种情况

```
1,0,1
0,0,1
0,1,1
```



> 问题：行化简法，用1式*某一倍数+2式，最终得到的结果会替换掉2式，但是为什么不能是替换掉1式？
>
> 是为了能更简化，还是说？
>
> 主元位置，主元，主元列还是有点懵，本就基本定义来说，不是很懂啦
>
> 尝试将高斯消去法用Python程序实现，明晚预定

## 3 向量方程

向量：仅含一列的矩阵被称为列向量，或者简称为向量

R<sup>2</sup> : 如果一个向量只有两个元素，可以用  R<sup>2</sup> 来表示 ,其中R表示这个向量里面的元素是实数，<sup>2</sup>表示该向量有两个元素
















# 一：向量

对于物理学来说，向量就是有长度，有方向的箭头

对于程序员来说，向量就是一维数组，可以用它来描述一维空间的位置

比如【1,2】就是建立一个直角坐标系，X轴坐标为1，Y轴坐标为2的点

## 1.1向量的加法

假设有两个向量

`[1,2]`  `[2,3]`

其两个向量的加法就是`[3,5]`,也就是X轴坐标相加，Y轴坐标相加

为什么会这么算呢？

这需要图形的直观认识

总的来说，我们可以在一个直角坐标系里面画两个向量

# 二：机器学习

机器学习有很多种算法，以下介绍几个

## 2.1 监督学习

在监督学习中，我们一般都有一个数据集，并且知道正确的输出是什么，还知道输入和输出存在联系

### 2.2.1 回归问题

回归问题指的是，给定一个算法和一个正确的数据集，让机器去学习这个数据集，以便可以预测一个连续集的输出

比如说，现在有一个房价的数据集（里面包含每平方米对应的房价），现在要求出X面积下，房价是多少。

那么首先就是根据算法绘出一条拟合曲线（可以是直线也可以是曲线，实际上是一个连续函数）

去拟合那些房价数据。

然后通过这个拟合线，去对应要求的房价面积，从而得到房价。

监督学习，又叫回归问题

**怎么定义这个连续函数呢？**

首先假设我们要拟合的线是一条直线。

对于直线的函数，定义是`y=c1+c2x`

我们要求出c1和c2的最优解是多少。

而找最优解的方式，就是代价函数





### 2.2.2 分类问题

根据给定的数据集，将数据集分为几个类别，可以预测输入的数据，是属于何种类别

比如现在有一个肿瘤样本，样本里面包含了以下几个属性

1. 肿瘤大小
2. 病人年龄
3. 是否恶性

分类问题就是会有一个新病人，他的肿瘤大小和年龄是已知的，求肿瘤是恶性肿瘤的概率。

像这个问题，机器学习会将恶性/非恶性肿瘤分开来，然后预测新数据是恶性还是非恶性

嗯。实际的分类问题不止肿瘤大小/年龄这两个特征，甚至分类也不仅是恶/非恶这两个类型。

它们是可以多种多样的。

> 特征甚至可以多到计算机内存存不下，这个时候怎么办呢？
>
> 有一种东西叫向量机，据说可以处理无限的特征

## 2.2 无监督学习

无监督学习，就是只甩给机器一段数据集，要求机器自动将数据分类（这将用到聚类算法）

由于我们都不知道这些数据是什么，和前者监督学习的，拥有正确的数据集形成对比，所以。

这个问题就被成为无监督学习了

### 2.2.1 聚类学习

就是将数据自动分类，比如说给一大堆新闻，让机器自己去将新闻分类



## 2.2.2 非聚类学习

使用鸡尾酒会算法在混乱的环境中寻找个体

嗯，它可以帮你找到源数据集中，蕴含的分类，比如说，在一堆纷杂的语音当中，抽取出只属于某人的说话声。

这个功能的实现只需要一行代码

`[W,s,v]=svd((repmat(sum(x.*x,1),size(x1),1).*x)*x')`

svd方法是奇异值分解