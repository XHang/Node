# 数学

# 一：线性代数

关键字：

线性方程：形如  a<sub>1</sub>x<sub>1</sub>+a<sub>2</sub>x<sub>2</sub>+a<sub>3</sub>x<sub>3</sub>+....+a<sub>n</sub>x<sub>n</sub>=b

其中a<sub>1</sub> ，a<sub>2</sub>....和b是常数

其他是未知数



线性方程组：就是几个线性方程在一起组成一个方程组

解集：方程组所有的解被称为解集

一个线性方程组的解只有以下三种情况

1. 有无穷解
2. 仅有唯一解
3. 无解

系数矩阵：就是把线性方程组的系数弄下来，形成矩阵

矩阵的一行就是第一个线性方程的系数集合

增广矩阵：比系数矩阵多了一列，里面放“=”右边的常数

矩阵的三种基本的行初等变化

1. 倍加变换，就是把矩阵的第j行，乘以某一倍数，再加到矩阵的第i行上。

   举例子
   
   ```
   1，-2，1，0
   0，2，-8，8
   -4，5，9，-9
   ```
   
   现在把第一行乘以4，得到
   
   `4,-8,4,0`
   
   接下来用这个新行加上最后一行。得到新的矩阵是
   
   ```
   1，2，1，0
   0，2，-8，8
   0,-3,13, 9 
   ```
   
   这就是倍加变换了。
   
   其实是从解线性方程组得到的
   
   x<sub>1</sub>-2x<sub>2</sub>+x<sub>3</sub>=  0
   2x<sub>2</sub> -8x<sub>3</sub>= 8
   -4x<sub>1</sub>+ 5x<sub>2</sub> + 9x<sub>3</sub>= -9
   
   将第一个方程乘以4，然后加在第三个方程，以求消掉x1
   
2. 对换交换（就是将矩阵的两个行交换位置）

   对应到线性方程组上，就是交换两个线性方程的位置

   大概这样更顺眼一点。。

3. 将矩阵的某一行乘一个非零的倍数。

   没啥好说的，就是字面意思，

以上初等变换，都是从解线性方程组的过程中总结而来的



两个矩阵行对价：就是A矩阵经过初等变换，可以变成另一个矩阵，则两个矩阵就是行对价



行变换是可逆的，也很容易理解



如果两个线性方程组的增广矩阵是行等价的，则他们有相同的解集



其实我们可以通过增广矩阵，来得知对应的线性方程组是否有唯一解，无解，或无限解

将增广矩阵用行初等变换算到一定程度后，再换算成线性方程组，可能会得到一个矛盾的解集，那么就说明这个线性方程组是无解的



三角矩阵：矩阵内非零系数排列起来像是三角形一样

# 一：向量

对于物理学来说，向量就是有长度，有方向的箭头

对于程序员来说，向量就是一维数组，可以用它来描述一维空间的位置

比如【1,2】就是建立一个直角坐标系，X轴坐标为1，Y轴坐标为2的点

## 1.1向量的加法

假设有两个向量

`[1,2]`  `[2,3]`

其两个向量的加法就是`[3,5]`,也就是X轴坐标相加，Y轴坐标相加

为什么会这么算呢？

这需要图形的直观认识

总的来说，我们可以在一个直角坐标系里面画两个向量

# 二：机器学习

机器学习有很多种算法，以下介绍几个

## 2.1 监督学习

在监督学习中，我们一般都有一个数据集，并且知道正确的输出是什么，还知道输入和输出存在联系

### 2.2.1 回归问题

回归问题指的是，给定一个算法和一个正确的数据集，让机器去学习这个数据集，以便可以预测一个连续集的输出

比如说，现在有一个房价的数据集（里面包含每平方米对应的房价），现在要求出X面积下，房价是多少。

那么首先就是根据算法绘出一条拟合曲线（可以是直线也可以是曲线，实际上是一个连续函数）

去拟合那些房价数据。

然后通过这个拟合线，去对应要求的房价面积，从而得到房价。

监督学习，又叫回归问题

**怎么定义这个连续函数呢？**

首先假设我们要拟合的线是一条直线。

对于直线的函数，定义是`y=c1+c2x`

我们要求出c1和c2的最优解是多少。

而找最优解的方式，就是代价函数





### 2.2.2 分类问题

根据给定的数据集，将数据集分为几个类别，可以预测输入的数据，是属于何种类别

比如现在有一个肿瘤样本，样本里面包含了以下几个属性

1. 肿瘤大小
2. 病人年龄
3. 是否恶性

分类问题就是会有一个新病人，他的肿瘤大小和年龄是已知的，求肿瘤是恶性肿瘤的概率。

像这个问题，机器学习会将恶性/非恶性肿瘤分开来，然后预测新数据是恶性还是非恶性

嗯。实际的分类问题不止肿瘤大小/年龄这两个特征，甚至分类也不仅是恶/非恶这两个类型。

它们是可以多种多样的。

> 特征甚至可以多到计算机内存存不下，这个时候怎么办呢？
>
> 有一种东西叫向量机，据说可以处理无限的特征

## 2.2 无监督学习

无监督学习，就是只甩给机器一段数据集，要求机器自动将数据分类（这将用到聚类算法）

由于我们都不知道这些数据是什么，和前者监督学习的，拥有正确的数据集形成对比，所以。

这个问题就被成为无监督学习了

### 2.2.1 聚类学习

就是将数据自动分类，比如说给一大堆新闻，让机器自己去将新闻分类



## 2.2.2 非聚类学习

使用鸡尾酒会算法在混乱的环境中寻找个体

嗯，它可以帮你找到源数据集中，蕴含的分类，比如说，在一堆纷杂的语音当中，抽取出只属于某人的说话声。

这个功能的实现只需要一行代码

`[W,s,v]=svd((repmat(sum(x.*x,1),size(x1),1).*x)*x')`

svd方法是奇异值分解