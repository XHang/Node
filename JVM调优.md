# JVM 调优

# 第一章：概述

想继续JVM调优，必须先理解JVM虚拟机的内存模型

总的来说，JVM的堆内存在物理上分为两部分

1. **Young Generation** （年轻一代）
2. **Old Generation** （老一代）





# 第二章：年轻一代

young Generation是所有新对象创建的地方

当young generation 充满时，垃圾回收就会开始执行

> 这种垃圾回收被称为`Minor GC`

Young Generation分为三个部分

即一个`Eden Memory` 和两个`Survivor Memory`

有关Young Generation的几个重要观点

1. 绝大多数新对象创建的内存区域，都是在`Eden Memory`里面

2. 当`Eden Memory`充满时，JVM会执行`Minor GC` ,并将还存活的对象全都移动到其中一个

   `Survivor Memory`内存区域中去

3. `Minor GC` 也会检查`Survivor Memory`内存区域中存活的对象，并将其移动到另一个`Survivor Memory`内存中。所以每次执行完后，其中一个`Survivor Memory`内存区域总是空的

4. 经过多次`Minor GC`的摧残后还能活下来的对象，将被移动到养老院，也就是**Old Generation** （老一代）的内存空间。

   到底有多少次`Minor GC`呢？这就涉及到一个门槛问题了   ​
# 第三章：年老一代

Old Generation 内存中包含的对象一般都是活的很久，并经过多次的垃圾回收后还存活的。

通常垃圾回收是在Old Generation的内存满的时候中执行的。

Old Generation的垃圾回收又被称为`Major GC` 通常需要更多的时间

# 第四章 ：垃圾回收

一个很重要的特性：

所有垃圾回收都是`时间静止`时间，也就是说，当垃圾回收执行时，所有应用程序线程都会停止，直至操作完成

# 第五章:性能测试

一般来说,软件开发的传统过程是这样的

分析-设计-编码-测试.

但是测试仅仅只是测试功能是否满足需求.

至于性能或者扩展性,那是之后的事了.

当然这样可不行,所以后来才会出现性能测试分析阶段.

要通过这个阶段测试性能是否满足要求

如果不满足,需要返回分析,设计,编码的某个阶段.具体探讨是哪一部分导致了性能问题.

如果满足了,产品才可以继续发布.

当然在需求文档中,必须要有性能需求,不然探讨性能优化就毫无原因了.

举几个吞吐量和延迟性需求

1. 应用预期的吞吐量是多少?

2. 请求和响应之间的延迟预期是多少?

3. 应用支持多少并发任务

4. 把并发任务达到最大值时,应用程序可接受的吞吐量和延迟量是多少?

5. 最差情况的延迟量是多少

6. 如果要使垃圾收集导致的延迟控制在可容忍访问内,

   则垃圾收集的频率应该设计为多少








# 第六章:性能调优方案

## 3.1 定义

改善性能一般涉及到三种不同的活动

1. 性能监控

   指的是非侵入式的收集应用的性能数据的活动.

   一般在找不到性能问题的根本原因时,使用这种方法

   由于是非侵入式,可以在开发,测试,生产环境中使用

2. 性能分析

   这是一种侵入式的收集性能数据的活动,会影响应用的吞吐性或者响应性

   通常在性能监控后执行

3. 性能调优

   这是为了改善应用响应性或者吞吐性的而更改参数,源代码,或者属性配置的活动.

   一般在性能监控或者性能调优后执行

## 第一种:自顶向下

简而言之,就是从软件的栈顶层应用,从上到下一步步寻找优化机会和问题

应用开发人员常用这种方式.

这种方式一般是从发现性能问题的区域(负载)开始监控应用.

监控的范围包括操作系统,JAVA虚拟机,JAVAEE容器以及应用的性能测试统计指标

基于监控信息,来开展下一步工作,比如JVM垃圾收集器调优,JVM命令行选项调优

操作系统调优.





## 第二种:自底向上

就是从最底层的CPU指令数据(比如说CPU高速缓存未命中率,CPU指令效率)开始,逐渐上升到应用的架构上.

将应用迁移到其他操作系统时,或者应用以及部署到生产环境时,也常常使用这种方法

自底向上需要收集最底层CPU的性能统计数据

​	包括执行特定任务所需要的CPU指令数(通常称为路径长度 Path Length)

​	应用在一定负载下运行的CPU高速缓存未命中率.

自底向上一般关注的是不改动应用的情况下,改善CPU使用率.不过通常自底向上也可以为如何修改应用提供建议

# 第七章:选择合适的CPU架构

有时候，性能差仅仅是运行的ＣＰＵ架构或者系统不合适．所以，为应用选择一个合适的ＣＰＵ架构就显得尤为重要．

一般来说，**如果你的应用会有比较多的并发线程，那么推荐的ＣＰＵ架构就是每核多硬件线程**

系统会把每一核的每一个硬件线程都看作一个处理器．

这样的话，在发生长延迟时，比如说ＣＰＵ高速缓存未命中,如果同一个ＣＰＵ核中还有其他就绪的硬件线程，

那么，在下一个时钟周期，就会让这个硬件线程运行，从而减少等待时间．

相反，如果你用的是每核单硬件线程，当发生长延迟事件，就只能等事件完成而浪费时间周期．

并且，如果其他线程已经就绪却没有可用的硬件线程，那么运行前就必须进行线程的切换，而切换，一般要数百个时钟周期．

但是，对于不需要大量并发的应用而言，就没必要选用每核多硬件线程的ＣＰＵ，何况这种ＣＰＵ，它的时钟频率通常比较低，比单核单硬件线程的还要低．

**这种应用的话，还是老老实实选用单核单硬件线程的ＣＰＵ吧**

> 为了评估单核多硬件ＣＰＵ的性能，一般是要加载大量的并发线程的
>
> 另外，单核多硬件线程的ＣＰＵ典型代表型号是Ｏｒａｃｌｅ公司出品的ＳＰＡＲＣ T 系列处理器

# 第八章：操作系统的性能监控

## 5.1 cpu使用率

毋庸置疑,想让应用的性能达到最高,就必须充分榨干CPU周期.

> 值得注意的是,应用消耗很多CPU并不意味着性能达到最高

要找出应用如何使用CPU周期,就要监控CPU使用率.

CPU使用率分为两种

1. 用户型CPU使用率:指的是执行应用程序代码的时间占总CPU时间的百分比

2. 系统型CPU使用率:应用执行操作系统设备调用的时间占总CPU时间的百分比.

   这个CPU使用率高的话,说明应用有共享资源竞争或者IO设备之间有大量的交互

理想情况下,系统型CPU使用率为0时,应用会达到最高的性能.

但是理想是达不到的,我们只能尽量降低系统型CPU使用率

### 5.1.2 监控CPU使用率的工具：Ｌｉｎｕｘ

1. 图形界面

ＬＩＮＵX可以使用ＧＮＯＭＥ System Monitor

通过这个命令启动

`fdggnome-system-monitor ` 

据说只能普通用户启动，超级用户看不到资源和文件系统的栏目

听说还可以用ｘｏｓｖｉｅｗ看ｃｐｕ使用率，但是我用了之后就死机了．．

2. 命令行

   通常用`vmstat`来监控ＣＰＵ使用率，听说加个-w参数会比较好哦

   另外，显示出来的us 是用户型ｃｐｕ使用率，sy是系统型cpu使用率，id是cpu空闲率

   也可以用ｔｏｐ监控ＣＰＵ使用率使用率

   ​

##　5.2:番外篇

对于计算密集型应用，还要关注它的每时钟指令数以及每指令时钟周期．

> 一般平台提供的ＣＰＵ使用率监控是看不到每时钟指令数以及每指令时钟周期的
>
> 所以需要其他骚操作来监控这两货

这是因为即使ＣＰＵ在等待内存中的数据，操作系统工具还是会说ＣＰＵ繁忙．

这种情况被称为停滞，这种停滞还会浪费数几百个时钟周期．

想要提高计算密集型应用的性能时，就要尽量减少停滞和提高ＣＰＵ高速缓存使用率

## 5.3:CPU调度程序运行队列

除了cpu使用率之外,监控cpu调度程序运行队列对于分辨系统是否满负荷也是具有重要的意义.

如果调度程序运行队列很长,则表名系统可能已经满负荷.

当系统运行队列长度等于虚拟处理器个数时,用户不会感受到性能下降.

> 虚拟处理器个数=系统硬件线程个数=Runtime.getRuntime().availableProcessors();

如果系统运行队列长度达到虚拟核心数的4倍或者更多时,系统的响应就很迟缓了

一般说来,只要队列的长度超过虚拟处理器个数的1倍,需要盯紧他,不需要采取行动

如果是超过3-4倍以及更高,就需要采取行动了.

行动1:增加cpu

行动2:研究可以减少应用运行所需cpu周期的葵花宝典,改进cpu使用率

​	比如减少垃圾搜集的频率或者采用更优的算法以减少cpu指令

### 5.3.1 linux上的监控调度程序运行队列

还是要请我们的老朋友`vmstat`

其结果的第一列`procs`就是运行队列长度



## 5.4:内存使用率

内存使用率当然也是衡量性能的一个重要指标.

当运行所需内存超过物理可用内存时,就会发生页面交换.

就是将不常用的内存放进磁盘的swap空间.当要访问到这部分内存时,就要把它从磁盘上置换到内存中,而这种置换会对应用的响应性和吞吐量造成很大的影响.

而且,JVM垃圾搜集器受其系统页面交换,性能也会很差.

其一是因为垃圾搜集要占用很多内存

其二由于占较多内存,则java堆内存的一部分可能会发生页面交换,而垃圾搜集时又得置换进内存以便垃圾收集器扫描存活对象.这使得垃圾搜集会占用更多时间.

其三:垃圾搜集时所有java的应用都要停止.然后你懂得

经验:如果垃圾搜集的时间变长,则表明系统可能正在进行页面交换.

为了验证这一点,必须监控系统的页面交换

### 5.4.1:监控内存使用率:linux

还是老朋友`vmstat`命令,其中`free`列就可以监控页面交换.其实它显示的是空闲内存

要关注的还有`si`和`so`列,分别表示内存页面换入和换出的量.

要留意是否会出现空闲内存少,并且页面调度频繁的情况,相比而言,数量并不是很重要..

## 5.5:监控锁竞争

一般情况下，锁都应该是很快获取，很快释放．如果要是遇到有一个线程，迟迟不释放锁，那么其他需要锁的程序就只能空转，不断的尝试获取锁，这样对系统的性能会有较大影响．

接下来，我们就要找出Ｊａｖａ应用中的锁竞争．

首先来了解一些java1.5之后推出的锁竞争，它是怎么运作的

应用通过忙循环自旋尝试获取锁，如果若干次忙循环自旋都不能获取到锁，那么线程挂起，直到下次唤醒时再尝试获取该锁．

而线程挂起和唤醒都会造成`让步式上下文切换`这种切换通常会浪费数万个时钟周期．

那么怎么看程序是不是遇到了锁竞争呢？

对于任何java应用来说，如果让步式上下文切换占用它５％或者更多的时钟周期，说明它遇到了锁竞争

> 顺便说一下抢占式上下文切换，这个切换表明线程由于ＣＰＵ分配的时间片用尽而被迫放弃执行权或者被更高优先度的线程所抢占．和让步式上下文切换不同，后者是自愿放弃ｃｐｕ执行权的
>
> 可以通过`pidstat -w`　查看抢占式上下文切换的数值
>
> 如果抢占式上下文切换的数值较高，则表明系统会有较多的预备运行线程数．
>
> 引发的问题可以看下5.3:CPU调度程序运行队列
>
> 像这种问题的解决方案
>
> 1. 创建处理器组并将应用分配给处理器组运行,linux可以通过`taskset`命令完成
> 2. 减少应用运行的线程数
> 3. 分析应用，优化性能（不常用）

### 5.5.1查看Ｌｉｎｕｘ上的锁竞争

可以通过这个命令来查看`pidstat`

该命令可能需要安装`sysstat`

该命令显示的`cswch/s`就是应用的让步式上下文切换．

根据这个数值怎么判断应用已经遇到了锁竞争呢？

1. 用该`数值*80000`这就是应用由于让步式上下文切换而兰妃的时钟周期

   > 80000就是一个让步式上下文切换而浪费的时钟周期，当然只是估算而已

2. 用得出来的结果除以ＣＰＵ每秒的时钟周期数，就是让步式上下文切换占用的可用时钟周期

   > CPU每秒的时钟周期数，如３Ｇhz CPU每秒的时钟周期数就是`3000000000`

如果发现应用确实存在锁竞争，那么接下来就是在源代码中查找那一部分是有竞争锁的．

一般来说，都是要定期转储线程，查找锁竞争的线程

## 5.6 线程迁移

待处理的线程在处理器之间进行迁移也会导致性能下降．

一般来说，待运行的线程都会分配给上次运行它的处理器。

如果这个处理器正忙，那么将会把待运行的线程迁移到其他处理器上。

这个迁移也会降低应用的性能，这是因为迁移后的处理器一般没有这个线程需要的缓存。

降低线程迁移的一个办法就是创建处理器组并将应用分配给处理器组

一般情况下，如果横跨多核或者虚拟处理器的Ｊａｖａ应用每秒迁移超过500次，那么把应用绑定在处理器组是非常用的。

## 5.7 网络ＩＯ使用率

分布式Java应用的性能受限于网络带宽或者网络io的性能。

所以我们需要监控应用的网络使用率。

在linux上，可以使用这个命令`nicstat` 它可以报告网络使用率和网络接口的饱和度

命令输出的列名含义如下

`Int`网络接口设备名

`rKb/s`每秒读取的ＫＢ数

`wKb/s`每秒写入的ＫＢ数

`rPk/s`每秒读取的包数

`wPk/s`每秒写入的包数

`rAvs`，每秒读取的平均字节数

`wAvs`每秒写入的平均字节数

`%Util`网络接口使用率

`Sat`饱和度

怎么考虑优化网络ＩＯ使用率

单次读写数据量小的网络读写数据量大的应用会消耗大量的系统态ＣＰＵ，产生大量的系统调用

当然想优化的话，就要尽量减少网络读写的系统调用。

使用非堵塞的应用框架NIO也可以显著改善网络性能。

建议使用nio框架而不要使用jdk自带的nio实现，它只是一种原始实现。

## 5.8 磁盘ＩＯ使用率

对于有磁盘操作的应用来说，改善性能，自然就要监控磁盘ＩＯ

linux上可以使用`iostat`来监控磁盘ＩＯ使用率

该命令可以监控磁盘IO使用率和系统态cpu使用率

其中`%system`是系统态ＣＰＵ使用率，然后`%util`是磁盘IO使用率

但是这个命令并不能看出是哪个应用在操作磁盘。

直接跳过吧。。。

### 5.8.1 怎么优化磁盘ＩＯ使用率？

1. 更快的存储设备

2. 文件系统扩展到多个磁盘？

3. 操作系统调优，缓存大量文件系统数据结构？

   此外，还有尽量使用带缓存的输入输出流来减少读写次数。

   以及开启磁盘缓存，可以改善严重依赖磁盘ＩＯ的应用的性能。

   但是如果一旦断电的话，可能会导致数据损坏



# 第九章：JVM概览

本章主要讲述的是jvm的架构以及它的主要组件

JVM主要有以下三个组件

1. JVM运行时
2. JIT编译器
3. 内存管理器

## 9.1 HotSpot　VM的基本架构

基本架构就是

垃圾收集器（可插拔）

JIT编译器（可插拔）

HotSpot VM 运行时

​	HotSpot VM 运行时为JIT编译器和垃圾收集器提供服务和通用的API,此外，它还为VM提供启动，线程管理

​	JNI(Java本地接口)等基本功能

内存相关

java堆内存的大小受限于HotSpot版本和操作系统

早期操作系统和hotspot的版本都比较小，所以能用的内存也会比较小

现在大不相同的了，特别是64位的HotSpot　VM 能用的java堆内存就更大

虽然64的寻址对一些应用可能有帮助，但是64的HotSpot有性能损失。

因为内部的java对象指针从32位变成了64位，导致cpu高速缓存行可用的oops变少，从而降低了cpu缓存的效率

不过后来加了压缩指针，使得64位的大内存和cpu效率可以兼得。要通过-xx:+UseCompressedOops开启。

### 9.2 HotSpot　VM运行时

这货担当许多职责。

1. 命令行解析

2. VM生命周期管理

3. 类加载

4. 字节码解释

5. 异常处理

6. 同步

7. 线程管理

8. java本地接口

9. vm致命错误

10. c++堆管理

#### 9.2.1 JVM命令行

它能做到:可以选定哪个编译器，哪张垃圾搜集器，指定java堆的大小

   命令行选项包含三种

1. 标准选项：要求所有虚拟机都必须实现的选项
2. 非标准选择：不强制要求所有虚拟机都必须实现 开头的选项带有`-x`
3. 非稳定选项 开头的选项带有`--x`

意义:命令行一般是用于控制JVM的内部变量

选项面面观1:

对于内部变量为布尔类型的选项来说,只需要添加或者删除就可以控制这些变量.

对于内部变量为布尔类型的非稳定选项来说,选项前面的`+`或者`-`代表true或者false

例如`--x:+AggressiveOpts`就是设置某个内部变量为true以开启

​	`--x:-AggressiveOpts` 就是设置某个内部变量为false以关闭(默认值)

选项面面观2:

有些选项长这个样子

`--x:OptionName=<N>`

<N>代表数字,像这种带数字的非稳定选项,数字后面都可以带k,m,g表示千,百万及十亿

选项面面观3:

有些选项长得别树一帜,如`XXaltJvm=<name>`

就是`-xx`和选项名之间没有分隔符

甚至有些选项`:` `=`也是没有的



#### 9.２.2 VM生命周期

本章主要讲的是java程序运行前,终止或者退出时,jvm做了什么事?

1. 启动

   jvm启动所用的组件是启动器.这启动器有四种

   1. linux系统下的jvm启动器`java`
   2. windows系统下的jvm启动器 `java` or  `javaw`
   3. JNI接口的JNI_CreateJavaVm启动内嵌的jvm
   4. javaws启动器,用于启动applet.`ws`即指的是`web start` 而术语`java web start`就是指`java ws`

   启动器做的操作有

   1. 解析命令行选项

   2. 设置堆的大小,设置JNI编译器

   3. 设定环境变量和读取classpath

   4. 如果,命令行选项里面有`-jar`那么启动器就从指定jar文件里面找`Main-Class`

      否则从命令行读取`Main-class`

   5. 使用java标准本地接口和方法在新创建的线程中创建VM

   6. 一旦创建好vm,那么就开始加在主类了,启动器也会从主类中获取到主方法的参数

   7. vm通过jni方法callstaticvoidmethod调用主方法,并将命令行选项传给他

      至此,jvm开始执行命令行指定的java程序了

2. 关闭

   jvm又做了什么事呢?

   1. 检查和清理程序或者方法执行过程中生成的未处理异常

   2. 调用java本地接口方法`DetachCurrentThread`将java main方法和jvm脱离

      每次脱离,线程数都会-1,所以java本地接口知道什么时候应该安全的关闭VM

      并能确保VM此时并没有执行的操作

3. 遇到错误关闭VM的过程

   当VM启动时,或者运行时遇到很严重的问题,会调用DestroyJavaVM方法停止VM

   过程是这样子的

   1. 一直等待,直到只有一个非守护线程执行(也就是当前线程)

   2. 调用java.lang.Shutdowm.shotdowm(),它会调用java上的ShutDowm钩子方法.

   3. 运行java上的ShutDowm钩子方法,停止一系列线程,并发出状态事件通知jvmTI,然后关闭jvmTI线程.

      最后停止信号线程

   4. 调用Hotspot的javaThread::exit()释放JNI处理块,移除保护页.将当前线程从已知的线程队列中移除.

      从此刻起,VM就无法执行任何java代码了

      > 保护页是不可访问的内存页,用于内存访问区域的边界

   5. 停止vm线程,并将vm线程带到安全点,并停止JIT编译器的线程

   6. 停止追踪jni,hotspot vm 及jvmti屏障

   7. 为那些仍然以本地代码运行的线程是设置标记`vm exited`

   8. 删除当前线程

   9. 删除所有输入/输出留,移除perfMenory(性能统计内存资源)资源

   10. 最后返回给调用者


#### 9.２.3 VM类加载

类加载用于描述类名或者接口名映射成class类对象的整个过程

这个过程有三个阶段:1. 加载 2.链接(验证,准备,解析) 3初始化

1. 加载:首先要从类的全限定名获取二进制字节流,定义java类,然后创建这个类的Class对象

   这个过程会抛出

   1. NoClassDefFound 找不到这个类的二进制流
   2. ClassFormatError or UnSupportedClassVersionError 语法检查出错
   3. ClassCircularityError 类的继承层次有错 ,比如说自己做爸爸,自己又做儿子
   4. IncompatibleClassChangeError 也是类的继承层次有错,比如说实现的不是接口,是类

   这个加载过程一般是由类加载器来完成的,可以使用系统自己提供的类加载器,也可以自己选择

   关于加载器的更多知识可以看下一章

2. 验证

   不能保证所有被JVM加载的Class都是经过javac编译过来的,为了保证虚拟机自身的安全,通常会对类进行验证

   验证包括以下过程

   1. 文件格式的验证,保证这个class文件的格式是符合规范的,并能被当前版本的虚拟机所识别.

      经过该验证,Class文件就会load到内存内

   2. 对元数据进行校验(对类中各个数据类型进行语法校验)

   3. 对类的方法体进行分析,保证方法体不会作出危害虚拟机的行为

   4. 符号引用验证,,对类以外的信息进行匹配性的校验

3. 准备

   该过程主要是为类变量在方法区分配内存,并设置初始值的阶段

   值得注意的是,设置的初始值不是在代码中已经写好的值,而是数据类型默认的初始值

   设置代码中写好的值是在初始化阶段才完成的

   > 比较特别的是,被static final修饰的变量(其实这种情况也叫常量啦),在准备过程中,值就会被初始化成指定的值

4. 解析

   解析阶段是对常量池中的符号引用转换为直接引用的过程

   > 符号引用就是Class文件在编译过程中,生成的三类常量
   >
   > 1.类和接口的全限定名
   >
   > 2.字段的名称和描述符
   >
   > 3.方法的名称和描述符
   >
   > 转换为直接应用的过程就是分析这些符号应用,翻译成直接引用,load到内存中
   >
   > 什么,直接引用又是什么鬼,嗯,就是能直接指向目标的指针.
   >
   > 如果有了直接引用,那么引用的目标一定在内存中了

   解析不一定在类初始化之前完成,也有可能是之后(将要被使用时才解析)

   根据符号引用的类型,有不同的解析方案

   1. 类或接口的解析:判断要解析的直接引用是数组类型,还是普通对象类型

   2. 字段解析:要查找的是简单名称和字段描述符都匹配的目标字段.

      先查找本类,查找到,over,没有,下一个

      查找父接口-祖父接口-如果没有,下一个

      查找父类-祖父类...直至找到

   3. 类方法解析,跟字段解析是一样的,多了判断方法是属于接口的,还是类的,以及是先搜索父类,再去搜索接口

   4. 接口方法解析,也是基本一样,不过接口方法没有父类,所以只从父接口一级一级向上查找即可

5. 初始化

   该过程就真正的执行了Java代码了,在这个过程,类变量会真正的赋上程序员给它的值,而不是默认的初始值了.

   该过程也是执行类构造器`<clinit>()方法`的过程

   几个小知识:

   1. 该方法是编译器自动收集类变量赋值动作和静态构造代码块合并之后产生的.

   搜集的顺序也就是语句在源文件中的顺序

   > 特别注意的是,静态代码块可以访问在它之前已经定义过的类变量
   >
   > 如果类变量定义在静态代码块后面,那么静态代码块只能赋值,不能访问

   2. `<clinit>()`方法在调用时会调用父类的`<clinit>()`,所以在虚拟机第一个被执行`<clinit>()`的类肯定是Object类,另外这个方法是编译时自动生成的..

   3. 不是所以的接口或者类都有`<clinit>()`方法,如果类没有静态代码块和类变量的赋值操作,那么编译器可以选择不生成该方法

   4. 接口不能使用静态代码块,但是仍然有类变量的赋值操作,所以还是可以生成`<clinit>()`方法的

   5. 执行接口的`<clinit>`方法时并不会调用父类的`<cliinit>`方法

   6. 接口的实现类执行`<clinit>`方法时并不会调用接口类的`<clinit>`方法

   7. `<clinit>()`方法是线程安全的,也就是说,活动线程没执行完`<clinit>()`方法的话,

      其他想执行这个方法的线程都得等,万一这个方法执行的过程很长,那么就会造成线程堵塞

   8. 什么时候会执行`clinit>()`方法呢?其实也是在问,什么时候会进行类的初始化呢?

      当类的方法或者字段被访问到时.---(个人观点)

      > 值得注意的是,调用子类去访问父类的字段时,子类并不会初始化
      >
      > 因为这个字段还是属于父类的,不是子类的

      完毕!

      ​

   ​

   ​

   ​

而这个过程需要hotspot vm和java se 类加载库来共同协作.

其中,vm负责解析常量池符号,这个过程需要加载,链接,然后初始化java类和java接口

**那么,什么时候会触发类加载呢?**

1. vm自身引发
2. Class.forName()
3. ClassLoader.loadClass()
4. 反射API以及JNI_FindClass引发类加载

> **关于类加载的几个小知识**
>
> 1. vm启动时,除了加载普通类,也会加载诸如java.lang.Object和Java.lang.Thread这些核心类
> 2. 加载类也需要加载它的所有超类和所有超接口
> 3. 作为链接阶段的一部分,类验证也需要加载其他类

#### 9.２.4 类加载器

对于我们程序员来说,类加载器总共就三种

1. 启动类加载器,这个是用c++编写的类加载器,是虚拟机的一部分

   这个类加载器负责加载jdk/jre/lib目录下面的,或者`-Xbootclasspath`参数指定的路径中类库

   对于许多包名是`java` or  `javax` 来说,这些包里面的类总是会委托给启动类加载器来加载

2. 扩展类加载器,负责加载`JDK\jre\lib\ext`目录中类

3. 应用程序类加载器,这个的话,负责加载classpath下面的类

   > 其实还不止这些类记载器,Oracle还规范了四五个类加载器,这里就不讲了

   java应用程序都是通过以上的类加载器进行加载的,我们也可以自定义自己的类加载器

   > 那么什么时候会用到自定义类加载器呢?

加载器有一个层次关系,又称双亲委派模型(这名字谁起的,怪异)

这个层次关系是这样的

启动类加载器<<<<<扩展类加载器<<<<<应用程序加载器<<<<<自定义加载器

> 其实这个是简化的层次关系,你要知道,类加载器不止这四种

当一个类加载器接收到类加载请求时,它会委派它的上一级类加载器去加载该类.

所以一般来说,所有类加载请求最终都会交由启动类加载器进行加载

> 不一般来说,如果上级的类加载器都不能加载该类,那只能由它自己尝试加载类了

这种机制被称为类加载器委派.

这种机制最重要的用处就是确定JVM中类的唯一性.

因为JVM中类的唯一性是由类的全限定名和类加载器来确定的

> 这你就懂了吧,为了确保jvm里面的类,其类名不会冲突
>
> 这也就意味着,就算类的全限定名相同,只要是由两个不同的类记载器加载的,那么就不是同一个类
>
> equals方法都是挂的,当然,这种情况java程序就不稳定了,必须杜绝这种情况

顺便提一下定义类加载器和初始类加载器

类的首个加载器被称为初始类加载器,然后这个初始类加载器会委托另一个类加载器去加载类.

这个真正加载类的类加载器被称为定义类加载器.

比如说,A类引用了B类,那么对B进行常量池符号解析的类加载器被称为A的定义类加载器,B的初始类加载器



#### 9.２.5 异常处理机制

异常会导致程序控制的非局部转移,从异常抛出的地方,转移到程序员指定或者异常被捕获的地方.

异常有两种情形

1:由同一个方法抛出和捕获异常

2:由调用方法捕获异常

第二中稍微有点麻烦,需要退栈才能找到合适的异常处理器,也就是捕获异常的地方.

有三种信息可用于查找异常处理器

1. 当前方法

2. 当前字节码

3. 异常对象


如前所诉,如果当前方法没有找到异常处理器,那么当前活动栈帧就会退帧.

直到找到合适的异常处理器,VM执行状态就会更新,然后跳转到异常处理器的代码继续执行  

异常可以由字节码,VM内部调用返回,以及JNI_调用返回或者java调用返回引发.

#### 9.２.6 解释器

jvm解释器是基于模板实现的.jvm启动时,vn运行时利用内部的TemplateTable中的信息在内存中生成解释器.

TemplateTable包含每一个字节码对于的机器码.

TemplateTbale定义了所有的模板,并提供了字节码的访问函数,每一个模板都描述一个字节码

jvm这种基于模板的解释器要好于switch语句循环的形式..

switch语句执行重复的比较操作,最差情况需要和所有的字节码进行比较.

解释器也可以在运行代码的同时.分析代码,检测程序中的重要热点,集中性能优化这些热点代码,避免编译那些很少执行的代码.这个是Hotoopt自适应优化的一个重要部分

> 这里所指的编译,是把字节码翻译成机器码,解释执行

#### 9.２.7 同步

广义上:同步是一种并发操作机制,用来预防,避免对资源不恰当的交替使用(竞争)

#### 9.２.8 线程管理

线程管理涉及到线程的创建到终止-整个的生命周期,以及vm线程中的协调

线程管理的线程包括:java代码创建的线程,直接与hotSpot关联的本地线程,hotSpot为其他目的创建的内部线程

1. 线程模型

   线程模型中,java线程会被映射为本地操作系统线程,当java线程开启时,也会随之创建一个本地操作系统线程

   同理,终止java线程时,也会销毁一个本地操作系统线程

2. 线程的创建和销毁

   在hotSpot vn中,引入线程有两种方式,

   1. 通过java.lang.Thread实例的start()方法.
   2. 通过jni将本地线程关联到hotSpot vn上

   hotSpot vn内部的很多对象,都和线程相关,拿出来溜一下

   1. java.lang.Thread实例用java代码来表示线程

   2. hotSpot内部用C++的JavaThread实例来表示一个java.lang.Thread实例

      但是JavaThread不仅于此,它还保存了其他线程状态的追踪信息.

      JavaThread用普通对象指针来引用保存了它所关联的java.lang.Thread实例

      java.lang.Thread实例也用原始整数的方式保存了JavaThread实例的引用

      JavaThread实例也保存了OSThread(操作系统线程)的引用.

      > 一思考,感觉还挺有意思的,c++代码是基于操作系统的,java代码是用c++代码实现的
      >
      > 所以Java的线程要映射到c++的线程,c++的线程要映射到操作系统的线程

      接下来讲一个Java线程的生命周期

      1. java线程启动,,同时也会创建JavaThread实例和OSThread的实例,以及一个本地线程
      2. 当所有的vm状态准备好时,启动本地线程
      3. 本地线程启动,也就执行的Thread里面的run方法
      4. run方法返回时
         1. 处理未处理的异常
         2. 终止该线程(这步会导致释放所有以分配的内存)
         3. 检测该线程结束时是否vm也要终止

3. 线程状态

   VM可以使用许多内部状态来表示线程现在正在做什么?

   从Hotspot vn 的角度上看,线程主要有以下四种状态

   1. 新线程:线程正在初始化的过程中
   2. 线程在Java中,线程正在执行java代码
   3. 线程在jvm中,线程正在jvm中运行
   4. 线程堵塞:线程由于某些原因:获取锁,等待条件满足,睡眠,阻塞性IO而被堵塞.

   还有一些其他的状态信息,这些信息有助于调试所用,主要由vm内部的c++对象,osThread

   维护,主要有这么几种

   1. MONITOR_WAIT:线程正在获取竞争锁
   2. CONDVAR_WAIT:线程正在等待hotSpot vn 使用的内部条件变量(没有和任何java对象关联)??
   3. Object_WAIT java线程正在执行WAIT()方法

4. vm 的内部线程

   哪怕是一个hello world 程序,都会导致jvm创建大量的线程.

   这些线程由vm库以及vm内部线程所产生,vm内部线程如下所示

   1. vm线程:它是以一个c++单例对象,负责vm操作
   2. 周期任务线程:也是一个c++单例对象,也叫WatcherThread,模拟计时器中断使得vm可以执行周期性操作
   3. 垃圾搜集线程:支持并发,串行,并行的垃圾搜集
   4. JIT编译器线程:负责运行时编译,将字节码编译成机器码
   5. 信息分发线程:等待接收进程发来的信号并将信息分发给java的信息处理方法

5. 安全点

   安全点是什么?不知道

   但是能知道的是,当hotSpot vm到达安全点时,所有Java执行线程都会被堵塞,本地代码也不能返回到Java代码.

   当到达安全点时,jvm可以进行很多操作,其中一种就是GC



#### 9.2.9 其他零碎知识

**jvm中的c++堆**:除了vm内存管理器和垃圾收集器所维护 java堆之外,jvm还维护了一个c++堆,用于存储Hotspot vm的内部对象和数据

**Java本地接口**:也就是俗称的JNI,它允许Java代码和其他语言编写的程序和库进行协作.

**VM致命错误处理**:

OutOfMemoryError是常见的vm致命错误

还有一个Segmentation Fault是常见的致命错误

> (Linux和Solaris,Windows等价的错误是Access Violation)

当发生vm的致命错误时,通常会生成hs_err_pid.log的错误日志文件.一般来说,它会生成在vm的启动目录下

这个文件的内容主要是内存镜像,可以很清楚的看到vm奔溃时的内存布局

> 提供-xx:ErrorFile可以设置日志文件的路径

#### 9.2.10 垃圾收集器

终于到了比较重要的一章:垃圾收集器.要知道,垃圾收集器运行的方式和执行的效率会对应用造成极大的影响

所以,性能优化中,垃圾收集器是需要着重了解的一章

首先了解一下一个垃圾收集器的算法:分代垃圾收集算法.

这个算法的设计基于两个观察事实

1. 大多数分配对象的存活时间都很短
2. 存活时间长的对象很少引用存活时间短的对象

这两个观察事实被称为弱分代假设,基于这个假设,jvm将堆分为两个物理区,这就是分代

物理区1:新生代:大多数创建对象都会分配在新生代中.对于整个jvm堆来说,新生代垃圾搜集比较频繁而且效率很高

​	这是因为新生代空间小,而且里面对象活不长,一波新生代垃圾搜集(记为Minor GC)就可以带着大量的狗带对象.

物理区2:老年代:Minor GC执行多遍之后仍然坚挺的对象会被放到老年代中.

​	老年代的空间比较大,但是占用增长的速度会很慢.

​	因此,相对于Minor GC而言,老年代的垃圾搜集(记为Full GC)执行频率会比较低,但是一旦发生,就够应用程序喝			    一壶的了

物理区3:永久代,这是vm物理区域的第三部分,虽然被称为代,但是其实不应该把它看做分代层次的一部分

> 也就是说,老年代的对象就别想跑到永久代的物理区域中存活了,该GC掉还是得GC掉

永久代一般用于存储元数据,比如说类的数据结构,保留字符串

> Minor GC还使用了一个叫做卡表的小策略,用于识别新生代的存活对象.
>
> 因为很多新生代的存活对象都是在老年代的存活对象有它的引用,它才可以存活下来的.
>
> 那要检查新生代的存活对象岂不是要扫描整个老年代,找出持有新生代对象的引用的老年代对象?
>
> 不用.老年代可以以512字节为块分成若干个卡.把这些卡当做数组的每一个元素,组成一个数组,就是卡表了.
>
> 每当老年代对象持有的新生代对象引用发生变化时,vm就必须将该老年代对象所在的卡标记为脏
>
> 然后在Minor GC中,只会扫描脏卡来识别新生代的存活对象

分代垃圾收集的优势

什么优势呢?就是啊,每一个分代都可以根据特性选择最适合它的垃圾收集器

对于新生代来说,使用的垃圾收集器一般选择速度快的,因为Minor GC执行频繁,而且只浪费一点内存空间

对于老年代来说:使用的垃圾收集器选择空间利用效率高的,但是速度慢的.因为老年代占的空间比较大.不过Full GC执行的频率低,所以也不是什么大问题

分代垃圾收集的优势仅当你的应用符合弱分代假设,它才可以发挥作用,否则适得其反.

不过,实践中,不符合弱分代假设的应用很少见.

#####　9.2.11新生代和老年代

上面所讲的新生代还不够仔细，其实，新生代还包含三个独立区域

1. Eden区:一般新创建的对象都会放在这里,不过也有例外,比如说,big对象就会直接放在老年代中
2. 两个Survivor区:这里存放的对象至少经过一次Minor GC,而且在跑路到老年代中还有不止一次的Minor GC

那么Minor GC主要干了什么事呢?

它首先会清空Eden区,并将存活的对象转到一个未被使用的Survivor区,同时,另一个Survivor区存活下来的对象也会复制到那个未被使用的Survivor区,然后,被占用的Survivor区存活时间长的对象会被转移到老年代.

> 这会引发一个问题,当未被使用的Survivor区无法接收太多的,来自Eden区和另一个Survivor区的存活对象的话.
>
> 就会导致溢出,多余的对象会被转移到老年代中,这个叫过早提升,会导致老年代空间占用增长迅速.
>
> 而一旦老年代满了的话,MInor GC就放不入存活的对象了.所以Minor GC之后通常就会进行Full GC
>
> 这会导致遍历这个java堆,也被称为提升失败

所以Minor GC之后呢,Eden区和其中一个Survivor区总是空的.

> PS:整个垃圾收集的过程都是在复制存活对象,所以这种垃圾收集器被称为复制,垃圾收集器

那么Full GC又干了什么事呢?

Full GC 收集整个堆,包括新生代,老年代,永久代

#####　9.2.12 快速内存分配

快速内存分配需要内存分配器和垃圾搜集器的准确配合．

垃圾收集器会记录搜集的空间，这个空间就可以给内存分配器参考，参考是否有空闲的内存区域可以容纳新的内存分配请求．

更详细一点的说,Minor GC之后,Eden和其中一个Survivor区总是空的.

这样的话,内存分配器就可以使用一个叫指针碰撞的黑科技,只需要检查最后一个分配的对象,记为top,和内存区末端

之间是否有空闲的空间,如果有的话,新分配的内存空间就放在top的后面.

> 类比一下瓶子装沙子,每次Minor GC后都会把沙子完全倒空,新来的沙子就直接洒在旧沙子的上面.

> 这样的话,就能保证瓶子的每一个空间都能得到有效的利用
>
> 不过,这个例子不太恰当..如果倒沙子的过程不干净的话.唔..不太能说明问题呢

另外,快速内存分配其实要考虑一个线程安全的问题的,如果有多个线程同时请求内存分配.

那么就要给内存分配这块加锁.这样的话,执行效率太慢了.

Hotspot使用一种叫做线程本地分配缓冲区技术(TLAB),为每一个线程分配缓存区(Eden的一部分),这样每一个缓存区只有一个线程在分配内存,可以采取指针碰撞的技术快速分配内存,不用加锁了.

当然,如果为线程分配的缓存区不够用咋办,这个时候,就需要加同步锁,不过很少见.

##### 9.2.13 Serial垃圾收集器

接下来的几章将讲解垃圾搜集器的几种类型

这章就先讲Serial收集器.

这种收集器在进行Minor gc时,采取的算法跟之前描述的垃圾收集算法是一致的,这里的就不讲了

但是在Full GC 中,采取的是滑动压缩标记-算法,所以也被称做压缩标记垃圾收集器

这个算法是这么处理的:

先收集老年代存活的对象,将它们推向堆的头部,然后留下堆尾部一段连续的内存空间.

这使得对于老年代的内存分配仍然可以采取指针碰撞的方式.

这种垃圾收集器适用于停顿要求不高,和在客户端运行的应用.它只用一个处理器进行垃圾收集(Serial之名由此而来)

它只需要几百兆java堆就能有效管理很多应用,而且在最差的情况下也能保持比较少的停顿..

同一机器运行多个jvm实例时也常用这个垃圾收集器

> ps:jvm进行垃圾收集时,最好只使用一个处理器处理,虽然这比较慢,但对其他jvm影响最小.
>
> 这一点Serial搜集器做的很好



##### 9.2.14 Parallel收集器(ThroughPut收集器)

该垃圾收集器可以加大应用程序的吞吐量,减少垃圾收集的开销.

它使用的算法和Serial垃圾收集器是一样的

> 也就是新生代使用之前描述的垃圾搜集算法
>
> 老年代使用标记,压缩方式

但是Minor GC 和 Full GC 使用的都是并行方式,可以使用所有可用的处理器资源.

这种垃圾收集器广泛用于

1. 需要高吞吐量的应用
2. 极端情况下Full GC 引起的停顿时间要求高
3. 运行在多处理器系统之上的应用.

与Serial处理器想比,Parallel处理器改善了垃圾收集器的效率,从而也提高了应用的吞吐性

##### 9.2.15 Mostly-Concurrent收集器

该垃圾收集器致力于低延迟的收集

该垃圾收集器在新生代垃圾收集和之前描述的,没什么特殊的

但是在Full GC 中,则是尽可能的并发执行,每一个垃圾收集周期只有两次小的停顿

一个垃圾收集周期会有四个阶段

1. 开始标记阶段:该阶段会标记所有外部可达的对象

2. 并发标记阶段,该阶段会标记从上一个阶段的对象可以到达的对象.

   > 其实在并发标记之后,重新标记之前,还有一个并发预清楚标记阶段
   >
   > 该阶段主要抢了重新标记的一些工作.
   >
   > 也就是重新遍历在并发标记阶段改动的对象.
   >
   > 虽然这个阶段之后重新标记仍然会进行,但是它减轻了重新标记的工作量,减少了由此产生的停顿

3. 重新标记,由于在并发标记阶段,应用可能还在运行,一些已经标记的对象的引用可能会发生变动.

   该阶段追踪那些变动的对象并进行最后的标记.

   > 怎么追踪呢?还记得之前谈过的卡表吗,同理的

4. 并发清除

   在这个阶段中,会清除这个Java堆,释放没有迁移的对象.

   但是由于并发,最后清除的空闲空间是不连续的,无法再用指针碰撞技术快速分配内存.

   只能用一个数据结构(HotSpot使用空闲列表)记录空闲的空间.

   这使得Minor GC 提升新生代对象时,会产生额外的开销

Mostly-Concurrent收集器的缺点

1. 如前所诉,这种垃圾收集器的Minor GC效率比较低

2. 需要更大的java堆,因为在整个垃圾收集周期中,只有清除阶段才会释放堆空间.

   而其他阶段,应用可能还在分配内存

3. 在三个标记阶段中,尽管这个垃圾收集器可以保证找到所有的存活对象,但是并不能保证能找出所有的垃圾对象

   在标记期间的垃圾对象,可能在本次周期清除阶段被清除,也有可能不被清除.

   侥幸躲过一次垃圾收集周期的垃圾被称为浮动垃圾.

4. 由于最后的清除阶段缺少压缩,会导致空间碎片化,因此垃圾收集器无法最大程序的利用所有可用的内存空间

5. 如果在一个垃圾收集周期时,还未回收到足够的空间,而老年代已经满了.

   那么收集器就会退而求其次,使用代价昂贵的Stop-The-World进行空间压缩.

   就像之前说的那两个垃圾收集器一样

该垃圾收集器适用于

1. 需要快速响应的应用,对吞吐量要求不是很高的应用
2. Full GC停顿要求时间少

##### ９.2.16: Garbage_first收集器

该收集器(缩写为G1)是为了替代上一个垃圾收集器.

它是一个并行的,并发的增量式压缩低停顿的垃圾收集器

这种垃圾收集器的堆布局和其他垃圾收集器的堆布局有着极大的不同的.

它把java堆分成相同尺寸的块(称为区域).

G1的几个特性

1. 虽然G1也分代,但是整体上并没有分为老年代和新生代

2. G1的每一代是一组区域(可能不连续),这使得它可以灵活分配哪一个是新生代

3. G1的垃圾收集是把区域中的存活对象转移到另一个区域.然后收集前者(通常前者占的空间更大)

4. G1大部分只收集新生区域(这些形成了G1的新生代),这种收集过程相当于Minor GC

5. G1有时也会并发标记那些非新生区域,而且是那种有很多垃圾的区域.

   然后回收它们,这通常会产生大量的可用空间

   这个策略就是:优先回收垃圾对象最多的区域,这也就是这个垃圾收集器的由来
##### 9.2.17 应用程序对垃圾收集器的影响

1. 内存分配

   应用内存分配的速率越快,垃圾收集触发的就越频繁.

   因为速率越快,就意味着分代占用的内存会很快挤满,新生代挤满来一发Minor GC

   老年代挤满来一发Full GC

2. 存活数据的多少

   一般说来,每个分代存活的对象越多,垃圾收集器要做的事也就越多

   因为Minor GC 是复制存活对象

   Full GC 是标记-复制-存活对象

   复制这么多的存活对象,你说垃圾收集器它累不累啊?

3. 老年代的更新

   如果老年代的对象的引用发生了变化,就会产生一个Old-To-Young的引用

   如果这在CMS的一次回收周期中发生了.这就会导致在预清除或者重新标记阶段就产生的一个需要的便利的对象

   > 一些对于优化垃圾收集器的效率的编码建议
   >
   > 1. 慎用对象池化,池化对象会长时间存活,占用老年代空间,初始化对其写操作也会增加老年代引用更新的数据
   > 2. 不合适的数组类数组尺寸.比如说ArrayList的数组尺寸过小,它内部的数组可能会频繁的扩充.导致不必要的内存

### 9.3 JIT编译器

编译是指从源代码生成机器码的过程.

传统的编译是先把源代码编译成二进制目标文件,然后再链接成可执行文件或者库文件.

Java的编译有所不同,它是先把Java源代码编译成类文件,然后送到虚拟机里面

> (或者搜集到jar文件里面再送进虚拟机)

虚拟机再动态的将字节码转成机器码.

编译器工作的流程

1. 由前端接收源代码-转成中间代码(IR)

   > 生成的中间代码通常是编译器优化最集中的地方

2. 后端接收这些中间代码-转成机器码

   这个过程包括指令选择,以及寄存器的分配

   指令选择可以由编译器作者直接处理指令选择,或者程序自己自动选择指令

   寄存器分配是指将寄存器分配给程序中的所有变量

   但是程序所有变量太多,寄存器数目太少,不能全部分配怎么办.

   这就牵扯到一个寄存器分配算法

   1. 轮循调度算法,对于简单的代码生成,用这个就行了,但也仅限于简单代码生成

   2. 图着色算法:这个主要是在堆中维护一个图表数据结构,里面用来表示哪些变量被同时使用,并且它们可以使用哪个寄存器.

      如果活跃的变量数超过了寄存器数,那么不重要的变量会被移动到栈中,使得其他变量可以使用寄存器.

      图着色算法可以使寄存器的使用率达到最高,并且多余的值很少被卸载到栈中.

      但是图算法花费的时间和空间都比较昂贵

   3. 线性扫描寄存器分配:它的目标是单趟扫描所有指令时指派寄存器.

      并且指派还不错.

      不过缺点是不能保证在变量的生命周期中,它都留在一个寄存器内.

   > 值从寄存器取下来叫值卸载,也叫寄存器卸载

#### 9.3.1 类的继承性分析

在面向对象的代码中,代码往往被分成一个个小方法.如果能将这些小方法内联起来,

代码运行效率就可以有很大的提升

> 为什么,如果不内联的话,正常代码要调用另一个方法的时候,需要保存现场,并记忆执行的地址.
>
> 调用完毕后要恢复现场,回到原来的地址继续运行,这样会有额外的开销
>
> 方法内联的意思就是把将要调用的方法,方法体转移到调用的地方..
>
> 这样就没有调用一说了,直接执行方法体就相当于调用了.

但是Java在处理内联方法上有点小问题,首先看下面一段代码

```
public interface Animal {
    public void eat();
}
public class Cat implements Animal{
    public void eat() {
        System.out.println("cat eat fish");
    }
}
public class Test{
    public void methodA(Animal animal){
        animal.eat();
    }
}
```

编译器想内联`methodA`中的`animal.eat();`方法,但是编译器知道这个方法实际上是哪个吗?

不知道,只有当运行的时候才能知道`animal.eat();`到底指的是`dog`的`eat()`还是`cat`的`eat`

那么这个时候编译器就通过CHA(类的继承性分析)假设当前只有一个类,也就是Cat这个类实现这个eat方法.

于是就把`methodA`中的`animal.eat();`方法和cat的`eat`内联起来.

当然,这种内联优化是相当激进了,一旦有新的子类加载进来,并且发现它实现了eat这个方法.

那么Hotspot VM就会通过逆优化把这个CHA假设丢弃.已经编译好的代码也会替换成解释器执行

#### 9.3.2 编译策略

由于JIT没有时间编译程序中的所以方法,所以一开始,程序都是在解释器上运行的.

如果一个方法调用太多次,那么可能就会编译这个方法.

那调用多少次呢,这就涉及到一个阀值,这个阀值通过方法调用计算器和回边计数器来计算

方法调用计数器在方法每次被调用时,都会加1

回边计数器在方法执行过程中,从后面的代码行跳到前面的代码行(比如说循环.经常跳回循环开始的地方)

就会加1.

这两个计数器每次递增,解释器都会和阀值进行比较,以确定要不要编译这个方法..

当发起编译请求时,如果编译器不忙,那么就可以开始编译,此时解释器还可以继续执行代码(计数器要清0)

> 如果你想等编译代码过程中,不要执行代码,可以使用`-Xbatch`或者`-XX:BackgroudCompilation`堵塞执行代码,直到编译完成

当编译的代码完成时,编译代码就会和方法关联,以便下次调用这个方法能执行编译好的代码.

不过上面的这些策略对于一个长时间的循环代码来说并没有什么卵用.

这时候就要用到一种栈上替换的技术,当循环代码长时间执行导致回边计数器溢出时

编译器就会编译循环开始的第一个字节码,直至整个循环(而不是从方法的第一个字节码开始,编译整个方法)

然后用栈上替换的黑科技让循环充分利用编译代码.

#### 9.3.3 逆优化

逆优化是指将若干个内联的编译帧转换成等价的解释器帧的过程.

这个过程可以将编译代码从多种乐观优化中回退回来(典型的乐观优化就是类的继承性分析)

或者当编译器遇到罕见陷阱时,也会使用逆优化.

JIT的逆优化会在安全点上保存一些额外的元数据,一些额外的元数据可以构件一组解释器帧使代码可以从解释器中继续运行.

#### 9.3.4 Client JIT编译器介绍

这个编译器的目标是更快的启动时间和快速编译,使客户不会为了应用糟糕的响应时间而纠结

它的历史

早期:概念类似与解释器,跟解释器一样会为每种字节码生成模板,也维护了一个栈布局,类似与解释器帧

​	仅支持类的字段访问方法内联.

Java 1.4:支持全方法内联,支持类的继承性分析(CHA),逆优化支持

Java5.咸鱼一条,没有重大改进

Java6:重大改进.IR(中间代码)改成了SSA分格,简单局部寄存器分配升级为线性扫描寄存器分配,内存优化

#### 9.3.5 Server JIT编译器

目标:应用性能达到极致,吞吐量也达到最高..

所以可见这个编译器就要不遗余力的进行优化,接下来就是它表演的时刻了

1. 极力内联,这通常会造成大方法,导致编译的时间边长
2. 使用扩展的优化技术，涵盖了大量的极端情况，要满足这些情况，就只能为每一个它可能遇到的字节码都生成优化代码


#### 9.3.6 静态单赋值-程序依赖图

这个看的有点懵，先占个位置，以后涨经验后再补

#### ９.3.7 正在开发的编译器

其实已经开发完成了吧，这个新的编译器名称叫做－混合式JIT编译器。

它糅合了Client JIT编译器和Server JIT编译器的特性，期望能达到快速启动，以及使用更多的优化技术。

#### 9.3.8  jdk各个版本的默认值以及自适应调优

1. jdk 1.4.32 的默认值

   垃圾收集器：使用Serial收集器

   JIT编译器：Client 

   Java堆初始化是4MB，最大值是64MB

2. jdk 5 默认值

   在jdk5时，引入了一个新特性-自动调优  使 Hotspot VM 可以根据系统的配置选择不同的默认值

   对于ThroughPut收集器来说，还可以根据程序运行的情况，自动调整堆的大小和内存分配的速率

   如果系统配置至少有2GB的物理内存和至少2个虚拟处理器的系统，那么Hotspot VM 采用服务类机器的默认配置

   1. 垃圾收集器：ThroughPut 垃圾收集器
   2. JIT编译器：Server
   3. 初始(最小)堆大小：物理内存的1//64(上限为1GB)，最大为物理内存的4/1

   > 要注意的是，32位的系统不适用服务类机器的定义。
   >
   > 这些系统使用默认的配置是
   >
   > 1. 垃圾收集器 Serial收集器
   > 2. Client编译器
   > 3. 最小堆内存4MB  最大堆内存 32MB

   想知道你当前的机子使用那些默认值吗？

   可以键入该命令`java -XX:+PrintCommandLineFlags -version`查看

   结果类似于

   ```
   -XX:InitialHeapSize=128791168 -XX:MaxHeapSize=2060658688 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 
   java version "1.8.0_161"
   Java(TM) SE Runtime Environment (build 1.8.0_161-b12)
   Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)
   ```

   可以看到

   1. -XX:+UseParallelGC  使用 ThroughPut(Parallel)垃圾收集器
   2. 初始堆内存`128791168`字节,最大堆内存`2060658688`字节
   3. 使用Server JIT编译器，可以通过这个信息`Java HotSpot(TM) 64-Bit Server VM `看到

3. jdk 6 默认值

   jdk6对非服务器类机器进行了优化，当JVM认为机器是非服务器类机器时，就会启动优化

   > 判断条件：物理内存低于2GB，虚拟处理器少于2个


   优化的内容是

   1. 编译器：还是Client
   2. 堆尺寸进行了优化
   3. 调整了垃圾收集器的设置

#### 9.3.9 自适应java堆调整

当JVM自动优化选择了ThroughPut垃圾收集器，就会开启一个`自适应堆调整`的优化

就是通过评估对象的分配速率和生命周期，试图优化新生代和老年代的堆大小。

使得存活期小的对象能被及时回收，允许时间长的对象适时提升，避免不必要的Survivor区的复制。

另，程序员可以指定初始值的新生代大小

`-Xmn`    `-XX:NewSize`    `-XX:MaxNewSize`   `-XX:NewRatio`  `-XX:SurvivorRatio`



自适应Java堆调整不一定适用于所有项目，对于项目的调整性波动，以及对象分配速率的迅速变动，对象生命周期的剧烈变化，自适应java堆调整反而会掉坑，这个时候，就应该关掉自适应调整优化了

`-XX:-UseAdaptiveSizePolicy`这个命令行参数就可以关掉了。

另外，如果第二个`-`变成`+`号，就变成了开启自适应优化了







   ​















uu